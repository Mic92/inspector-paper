\section{Overview}
\label{sec:overview}


We base our design on {\tt POSIX} threads, commonly referred to as
{\tt pthreads}, a widely used threading library for shared-memory
multithreading with a rich set of synchronization primitives.  


\myparagraph{Basic approach} At a high level, we record data provenance for a multithreaded execution by constructing a {\em Concurrent Provenance Graph (or CPG)}. Informally,  the CPG records three types of dependencies; namely, control, data, and schedule dependencies for the multithreaded execution. To record these dependencies, we divide thread execution into sub-computations. We record the execution trace to construct the CPG that tracks the {\em data flow} between the sub-computations, {\em control flow} for each thread execution, and threads interleaving or {\em schedule dependency}  in the multithreaded execution.

More specifically, the Concurrent Provenance Graph (or CPG) records a partial order $O = (N, \rightarrow$) among sub-computations with the following property: given a sub-computation $n$ (where $n \in N $)  and the subset of sub-computations $M$ that precede it according to $\rightarrow$, i.e., $M = \{M \subset N \mid \forall m \in M,$ $m \rightarrow n\}$, if the writes made by $m$ becomes visible to $n$ then the partial order $\rightarrow$ captures this possible data flow between sub-computations.




\myparagraph{Example} Using a simple example (shown in Figure~\ref{fig:simple-example}), we next explain how we record these dependencies for a shared-memory multithreaded program. The example considers a multithreaded execution with two threads ($T_1$ and $T_2$) modifying two shared variables ($x$ and $y$) using a lock. In the example, we assume that a thread execution is divided into sub-computations at the boundaries of synchronization primitives, such as {\tt lock()/unlock()}. (We explain the reason behind this design choice in $\S$\ref{sec:model}.) We identify these sub-computations as $T_1.a$ and $T_1.b$ for thread $T_1$, and $T_2.a$ for thread $T_2$.   To understand the dependencies that need to be recorded for the required partial order ($\rightarrow$), we showcase three cases for recording the control, schedule, and data dependencies.

The first dependency that we need to record is the {\em control flow} execution of each thread. In particular, we need to record the intra-thread execution order of sub-computations. For example, sub-computation $T_1.b$ follows $T_1.a$, and therefore, the control flow dependency records this partial order as $T_1.a \rightarrow T_1.b$. Additionally, we need to record the control flow path taken within a sub-computation. For example, sub-computation  $T_1.a$ has a conditional branch ({\tt if/else}) based on the value of {\tt flag}. We supplement the control flow dependency with all control paths taken by a thread within each sub-computation; i.e.,  all branches taken at run-time.

Secondly, we need to record the inter-thread {\em schedule} dependencies. The sub-computations can be interleaved in different order across executions because of the non-deterministic thread scheduling by the underlying OS. For instance, when threads acquiring the lock in the reverse order where thread $T_1.b$ gets to acquire the lock before $T_2.a$. In this case, the final value of $y$ is affected based on this new ordering. Therefore, we also need to record the schedule dependencies between sub-computations as part of the partial order. We record these schedule dependencies by tracking interleaving of sub-computations by recording the thread schedule (For example, $T_1.a   \rightarrow   T_2.a \rightarrow T_1.b $).

Lastly,   we need to record {\em data dependencies} between sub-computations as a part of the partial order. For that, we track read and write sets for each sub-computation, i.e., the set of memory locations read or written by the sub-computation, respectively. The data dependencies are recorded implicitly using read and write-sets, and the partial order recorded using the control and schedule dependencies: if we know what data is read and written by each sub-computation, we can determine whether a data dependency exists by following the partial order, i.e. if a sub-computation is {\em transitively} reading the data that was modified by a sub-computation that precedes it in the partial order $\rightarrow$ then there exists a read-after-write data dependency. 



\input{tables/simple-example}













 