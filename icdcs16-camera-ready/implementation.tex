\section{Implementation}
\label{sec:implementation}



This section describes the architecture and implementation of \projecttitle. We implemented \projecttitle as a dynamically linkable shared library for the GNU/Linux OS that can be loaded and linked  at runtime for {\tt POSIX} threads (replacing the \pthreads library). The application executables can simply link the library (without any recompilation) either using {\tt LD\_PRELOAD} or the {\tt -rdynamic} flag, specifying the path of the \projecttitle library.  The \projecttitle library exports the CPG as an extended interface in the {\tt perf} utility for supporting data provenance.   The architecture of \projecttitle (shown in Figure~\ref{fig:basicSystem}) consists of two main components: threading library ($\S$\ref{sec:impl-lib}) and OS support for \intelpt ($\S$\ref{sec:impl-OS}). We next describe these two components in detail.


\input{figure/figureTex/fig_system_basic}

\subsection{Threading Library}
\label{sec:impl-lib}
The threading library derives the data and schedule dependencies. The architecture of the threading library is shown in Figure~\ref{fig:lib-architecture}. 

 
\myparagraph{Memory protection} A central challenge of the implementation of the
algorithm is keeping track of the data dependencies for shared-memory accesses
by all possible interleaving threads. Since monitoring every load and store to
each memory word would be too costly, we instead rely on the OS's
(hardware-assisted) segmentation fault mechanism to keep track of reads and writes at the granularity of memory pages.

To derive the read and write sets during sub-computation execution,  \projecttitle~uses standard memory protection  mechanism and signal handlers. In particular, \projecttitle protects the address space using {\tt mprotect(PROT\_NONE)} at the beginning of each sub-computation. This forces a trap (and the corresponding OS signal) the first time a page is read or written to in a given sub-computation. The respective signal handler, which is implemented by the \projecttitle library, records the information about the access, and also resets the protection bits so that subsequent accesses to the same page by the same thread in the same sub-computation can proceed without generating a trap. 

However, a naive page protection mechanism raises an important problem because all threads in a process share the same virtual memory
structures (namely the TLB and page table entries with the respective protection bits). This makes it difficult to keep track of which
threads are responsible for which memory accesses or to enforce different protections for different threads. Otherwise, we need to re-protect the page after serving every load and store instruction causing a large number of segmentation faults. To address this problem, \projecttitle implements threads as separate
processes (an idea  proposed by Grace~\cite{grace-oopsla-2009} and  Dthreads~\cite{dthreads-sosp-2011}).

\myparagraph{Threads as processes} \projecttitle  implements threads as separate processes thus allowing each thread has its own private address space and control over the virtual
memory structures.   This gives us the ability to manipulate the page protection of threads individually while providing a simple way to implement the release consistency memory
model. In particular, \projecttitle uses the {\tt clone} system call to fork off a new process on {\tt pthread\_create()}. The process that implements the newly created thread (i.e., the child process) already
shares parts of the execution context with the parent process (which implements the calling thread) such as file descriptors and signal handlers. 
\input{figure/figureTex/lib-architecture}

But this raises a new problem, which is that, unlike threads, processes do not share their address spaces. We address this by taking advantage of the RC memory model we defined for \projecttitle, where threads share the updates only at synchronization points.  

\myparagraph{Shared memory commit} To implement the RC memory model, we use shared memory commit (originally proposed in distributed shared memory architectures such as TreadMarks~\cite{treadmark} and Munin~\cite{munin}) 
that allows threads to communicate at well-defined synchronization points.
Our shared memory commit is implemented using memory mapped files. In
particular, the virtual address ranges for the shared portions (globals and heap) of
the address space are mapped to memory mapped files, which are managed by the
\projecttitle library. These address ranges correspond to the heap and
the static (i.e., globals) regions.  During thread creation,
\projecttitle marks these address ranges as a private copy-on-write
mapping (using {\tt MAP\_PRIVATE} in {\tt mmap()}). The effect of this
is that whenever the child thread tries to write to a memory location,
the OS makes a thread-private copy of the memory page containing the
modification.  At synchronization points, the thread computes a {\em diff}
for each dirty page by performing a byte-level comparison between the
dirty page and the shared page. The deltas are then atomically
copied to the shared memory page; if there are overlapping writes
to the same memory location we resolve them using a last-writer wins policy.


\myparagraph{Input support} In addition to providing wrappers for {\tt pthreads} and {\tt malloc} related API calls, we also implemented shim layer for a number of input {\tt glibc} library calls  to record the data-flow from the input. For instance, we provide wrappers for {\tt mmap} for reading the input. In particular, the threading library differentiates between the {\tt mmap} calls made by the library itself and the target application. This allows us to record the mapping of the input file in the input address space. And, as described before, the library uses {\tt mprotect()} to derive the data flow from the input. 


\subsection{OS Support for \intelpt}
\label{sec:impl-OS}
To obtain the control flow dependencies, we use Intel Processor Trace (PT) ISA extensions. We next present the implementation details of the OS support for \intelpt. 


\myparagraph{Intel Processor Trace (Intel PT)}   \intelpt is an extension of Intel Architecture that logs information about software execution with minimal performance impact. The processor collects information such as control flow, execution modes and timings and formats it into highly compressed binary packets. Traditionally, Intel architectures provided Branch Trace Store (BTS) for tracing branch execution. However, BTS was slow and imprecise. Therefore, it was not adopted in practice. To overcome the limitations of BTS,  Intel recently introduced PT ISA extensions as part of the Broadwell  (also available in Skylake) micro-architecture.




\myparagraph{OS support} The \intelpt tracing facility is integrated into the operating system, which makes it possible to use  different trace buffers for different processes, and to make the facility available for non-root users.  In Linux this processor feature is exposed to the user-space as a Performance Measuring Unit (PMU) in the {\tt perf} event interface. We make use of the \intelpt PMU to derive the control flow dependencies. Figure~\ref{fig:pt-OS-support} shows the architecture for the OS support for \intelpt.

 \input{figure/figureTex/pt-os}

In particular, the {\tt perf} interface on Linux consists of a syscall, which gives back a file
descriptor. Events are accessed by obtaining buffers via {\tt mmap(2)} and can be
further controlled via {\tt ioctl()} syscall on the given file descriptor. Along with
interface the user-space {\tt perf} allows to dump and filter from these
buffers. In our case, this filtering is done by using Linux control
groups (also known as {\tt cgroups}). {\tt cgroups} is a kernel feature to apply constraint
like resource usage to a group of processes. It has the property, that by
default every child process belongs to the same process as its parent. Also for
{\tt perf\_events} such a {\tt cgroup} exists.

We create such a {\tt cgroup} exclusively for the application using \projecttitle. This is done because
our threading library causes applications using threads to create multiple
processes instead, whose process ids are not known in advance.

The subcommand {\tt perf record} is then used to dump the trace produced by \intelpt.
\intelpt generates a stream of TNT packets, which denotes the
conditional branches taken and TIP packets for indirect branches and function
returns. The data is referenced as a sample event in the {\tt perf} event list and
stored in a ring buffer called \emph{AUX area}. If perf tool cannot
keep up with processor trace it is possible (for example an interrupt occurs),
there will be gaps in the trace. 
(We provide a snapshot facility ($\S$\ref{sec:snapshot}) to overcome this limitation.)


After execution the result can be further processed by using a set of tools
for example {\tt perf script}. The branch information is still in a compressed
form and needs to be decoded. We make use of the Intel Processor Decoder Library for Intel PT  that is integrated in the {\tt perf} utility. 
To map the trace onto binaries, it needs access to executables and linked
libraries of the application. For that, we track mmap events to
know the location of each loadable during the execution. 

