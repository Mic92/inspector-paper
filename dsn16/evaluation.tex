\section{Evaluation}
\label{sec:evaluation}

In this section, we present an experimental evaluation of \projecttitle based on the implementation described in  \secref{implementation}. Our evaluation answers the following questions.

\begin{itemize}
\item What overheads does \projecttitle impose for recording data provenance of multithreaded executions? ($\S$~\ref{subsec:overheads})
\item How do these overheads scale with increases in the size of input data and computation size? ($\S$~\ref{subsec:scale-overheads})
\item What are the sources for the provenance overheads? ($\S$~\ref{subsec:quantify-overheads})
\end{itemize}



\subsection{Experimental Setup}
We first describe the experimental setup used for the evaluation.

\myparagraph{Experimental platform} We used an Intel Xeon processor based
multicore architecture as our host machine for our evaluation. The
host system consists of 8 cores (16 threads) of Intel(R) Xeon(R) CPU Processor D-1540
(12M Cache, 2.00 GHz) and 32 GB of DRAM main memory. The host
machine is running Linux with kernel 4.2.0 in 64-bit mode.


\myparagraph{Applications and dataset}  We evaluated \projecttitle with applications from two multithreaded benchmark suites: Phoenix 2.0 \cite{phoenix} and PARSEC 3.0 \cite{parsec}. Table~\ref{tab:apps} lists the applications used for the evaluation along with the input data and benchmark parameters.  





\myparagraph{Metrics: Time and Work}  We consider two types of measures to report the performance metrics: {\em time} and {\em work}. In a nutshell, time measurements reflect the end user perceived latency, whereas work measurements assess the overall resource (CPU) utilization.  More specifically,  time refers to the end-to-end computation time for the multithreaded applications. Work refers to the total computation performed by all threads, and it is measured as the cumulative CPU time for all threads. To measure work, we used the CPU accounting controller in cgroups to account the CPU usage of all threads. 

\myparagraph{Measurements} All applications were compiled using GCC 4.9.2 compiler with -$o3$ optimization flag. For all performance measurements, we report the average over 10 runs with minimum and maximum values discarded.



\begin{figure}[h]
\includegraphics[width=8cm]{figure/benchmarks-inspector.pdf}
\end{figure}

\begin{figure}[h]
\includegraphics[width=8cm]{figure/benchmarks-16.pdf}
\end{figure}

%
%\myparagraph{Performance metrics: Work and Time}  For each run, we consider two types of measures: \emph{work} and
% {\em time}. Work refers to the total amount of
%computation performed by all threads and is measured as the total
%run-time of all threads. Time refers to the amount of (end-to-end)
%run-time to complete the parallel computation. Both metrics are important
%and complementary: time measurements reflect the end user perceived latency,
%whereas work measurements assess the overall resource (CPU) utilization.

\subsection{Provenance Overheads}

\myparagraph{Overheads}

\myparagraph{Breakdown of overheads}

\subsection{\projecttitle Scalability}

\myparagraph{Overheads w.r.t. input size}

\myparagraph{Overheads w.r.t. computation size}


\subsection{Sources of Overheads}




